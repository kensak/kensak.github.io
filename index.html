
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>AIへ秒読み</title>
  <meta name="author" content="榊原 研">

  
  <meta name="description" content="人工知能、機械学習、自然言語処理のトレンドを追っかけるページ">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://kensak.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="AIへ秒読み" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">AIへ秒読み</a></h1>
  
    <h2>人工知能、機械学習、自然言語処理のトレンドを追っかけるページ</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:kensak.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/about">About</a></li>
  <li><a href="/blog">Blog</a></li>
  <li><a href="https://github.com/kensak">Projects</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/02/12/connectionist-brain-model/">脳のコネクショニスト・モデル</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-02-12T14:30:00+09:00" pubdate data-updated="true">2014-02-12</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="https://staff.aist.go.jp/y-ichisugi/j-index.html">産業技術総合研究所の一杉裕志氏のサイト</a>で
氏は大脳皮質の計算論的モデル BESOM を提案しています。
それは４つの機械学習技術（自己組織化マップ、ベイジアンネット、独立成分分析、強化学習）を
組み合わせたもので、
すでにプログラムがありソースコードも公開されています。
その機能はもちろんまだ実際の人間の脳の機能からは程遠いとはいえ、
ここまで具体的な脳のモデルを既知の技術の組み合わせにより提示できるということが、
機械学習の進歩を物語っていると思います。</p>

<p>実際の脳にできることを考えてみると、脳の機能をコンピューター上で実現しようとするときの必要条件が見えてきます。</p>

<p>例えば</p>

<ul>
  <li>ニューロンの活動（化学的な反応）の遅さにも関わらす
高速な処理が可能　→　大規模な並列計算が必要</li>
  <li>人間の赤ん坊はさまざまな映像の中から一塊の物体や親の顔を認識するようになる
→ 独立成分分析のような「抽象化」をおこなう仕組みが必要</li>
  <li>快を求め不快を避けるという動物に共通した性質を実現するには強化学習のような
 「報酬」という概念を含む機構が必要</li>
</ul>

<p>ここで思考実験として、脳のコネクショニスト（つまりニューラル・ネットを用いた）モデルを
人間の脳が持つ能力から逆算しながら構成するということを試みたいと思います。
つまり、知能の個体発生（認知の発達過程）をたどりながら、人間の脳が備えている能力と、
それをニューラル・ネットの手法によって実現する方法をボトム・アップに考えていきます。
さらに他のモデルや技術と比較し、共通点や相違点についても考察します。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/02/12/connectionist-brain-model/">続きを読む &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/01/13/knuth-shuffle/">ランダムな置換とクヌース・シャッフル</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-01-13T19:52:19+09:00" pubdate data-updated="true">2014-01-13</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>ニューラルネットをプログラムするときに、ランダムな置換
（ここでは $ 0 $ から $ n-1 $ までの数がランダムな順で並んだものと考えます）が
必要になることがあります。例えば、</p>

<ul>
  <li>SGD with minibatch において、サンプルの配列の中からランダムな順序で 100 ずつ、
順番に取り出したい。ランダムな置換を使って配列のインデックスをかき混ぜればよい。</li>
  <li>Dropout において、n 個の入力のうちランダムに選んだ半分を 0 にセットしたい。
それぞれの入力を確率 0.5 で 0 にするのではちょうど半分になるとは限らない。
ランダムな置換を使えば、$ n / 2 $ 未満の要素を選ぶことによりちょうど半分
をランダムに選ぶことができる。半分ではなく他の比率でも大丈夫。</li>
</ul>

<p>ランダムな置換を得るには <a href="http://en.wikipedia.org/wiki/Random_permutation">Knuth shuffles</a>
という便利なアルゴリズムがあります。これは $ 0, 1, \ldots, n - 1 $ という
シーケンスに対し、$i$ 番目と、$ 0, \ldots, i $ からランダムに選んだ $j$
による $j$ 番目とを入れ替える、という操作を $i = 0, 1, \ldots, n-1$ について
繰り返すというものです。</p>

<p>変数の初期化も同時にやってしまうのが以下のコードです。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2014/01/13/knuth-shuffle/">続きを読む &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/01/10/uploaded-charrecog/">CharRecog を GitHub にアップしました</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-01-10T22:20:53+09:00" pubdate data-updated="true">2014-01-10</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>ニューラルネットによる文字認識プログラム CharRecog を
<a href="https://github.com/kensak/CharRecog">GitHub にアップしました</a>。</p>

<h3 id="section">特徴</h3>
<ul>
  <li>C++ で作成。OpenCV の ANN_MLP クラスを参考に、コアの部分はゼロから書きなおしました。</li>
  <li>並列処理 : インテル TBB、OpenMP, C++ AMP などを使い、マルチコア CPU や GPU による並列処理をおこなっています。</li>
  <li>行列計算による高速化 : すべてのサンプル画像を処理する際、できるだけループを回さず一回の行列計算により処理をおこないます。</li>
  <li>さまざまな手法への対応 : autoencoding, convolutional layer, max pooling, maxout, dropout の各手法や
入力画像のランダムな affine 変換などに対応しています。</li>
  <li>ビルド済み実行ファイルでは float で計算をおこないますが、ソースを一ヶ所変更してリビルドすれば double にも対応します。</li>
  <li>学習された重みを画像として出力できます。</li>
</ul>

<p>すぐに使えるよう 64 ビット版のバイナリもアップしています。
MNIST 画像セットを使って autoencoding や dropout などの実験が簡単におこなえます。</p>

<p>今後も気になる手法があればインプリメントしていく予定です。
また、画像認識や言語処理のための高速なNNエンジンとしても使えるようにしていきたい。</p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/12/29/maxout/">Maxout: アクティベーション関数に Max を使う</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-12-29T23:26:44+09:00" pubdate data-updated="true">2013-12-29</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>とても似た内容の二つの論文を読んでみました。
多層パーセプトロンのアクティベーション関数としてシグモイドや tanh のかわりに max を使うと文字認識などでの認識率が上がる、という話です。</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/12/29/maxout/">続きを読む &rarr;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/12/29/first-post/">初ポスト</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-12-29T21:03:36+09:00" pubdate data-updated="true">2013-12-29</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>二日がかりでようやく Github + Octopress のサイトを立ち上げました。
</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/2013/12/29/first-post/">続きを読む &rarr;</a>
    </footer>
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/02/12/connectionist-brain-model/">脳のコネクショニスト・モデル</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/13/knuth-shuffle/">ランダムな置換とクヌース・シャッフル</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/01/10/uploaded-charrecog/">CharRecog を GitHub にアップしました</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/29/maxout/">Maxout: アクティベーション関数に Max を使う</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/12/29/first-post/">初ポスト</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>Categories</h1>
    <ul id="category-list"><li><a href='/blog/categories/ai/'>AI (1)</a></li><li><a href='/blog/categories/c-plus-plus/'>C++ (2)</a></li><li><a href='/blog/categories/opencv/'>OpenCV (1)</a></li><li><a href='/blog/categories/arugorizumu/'>アルゴリズム (1)</a></li><li><a href='/blog/categories/niyurarunetuto/'>ニューラルネット (3)</a></li><li><a href='/blog/categories/puroguramu/'>プログラム (1)</a></li><li><a href='/blog/categories/wen-zi-ren-shi/'>文字認識 (1)</a></li><li><a href='/blog/categories/lun-wen/'>論文 (1)</a></li></ul>
</section>
<section>
  <h1>Tag Cloud</h1>
    <span id="tag-cloud"><a href='/blog/categories/ai' style='font-size: 120.0%'>AI(1)</a> <a href='/blog/categories/c-plus-plus' style='font-size: 140.0%'>C++(2)</a> <a href='/blog/categories/opencv' style='font-size: 120.0%'>OpenCV(1)</a> <a href='/blog/categories/arugorizumu' style='font-size: 120.0%'>アルゴリズム(1)</a> <a href='/blog/categories/niyurarunetuto' style='font-size: 160.0%'>ニューラルネット(3)</a> <a href='/blog/categories/puroguramu' style='font-size: 120.0%'>プログラム(1)</a> <a href='/blog/categories/wen-zi-ren-shi' style='font-size: 120.0%'>文字認識(1)</a> <a href='/blog/categories/lun-wen' style='font-size: 120.0%'>論文(1)</a> </span>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/kensak">@kensak</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'kensak',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <a class="twitter-timeline" href="https://twitter.com/search?q=%23%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92" data-widget-id="417340959202885632"></a>
  <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+"://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");</script>
</section>



  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - 榊原 研 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  









<script>
(function(w,d){
    var c,e=d.createDocumentFragment(),f=d.getElementsByTagName("script")[0],
    a=function(a,b){if(!d.getElementById(b)){c=d.createElement("script");
    c.src=a;c.id=b||null;c.async=true;e.appendChild(c);}};


    a("//platform.twitter.com/widgets.js");


    a("//b.st-hatena.com/js/bookmark_button_wo_al.js");
    f.parentNode.insertBefore(e,f);
})(this,document);
</script>

</body>
</html>
